embedding_size: 64              # (int) The number of features in the hidden state.
inner_size: 256                 # (int) The inner hidden size in feed-forward layer.
n_layers: 2                     # (int) The number of transformer layers in transformer encoder.
n_heads: 2                      # (int) The number of attention heads for multi-head attention layer.
hidden_dropout_prob: 0.5        # (float) The probability of an element to be zeroed.
attn_dropout_prob: 0.5          # (float) The probability of an attention score to be zeroed.
hidden_act: gelu                # (str) The activation function in feed-forward layer.
layer_norm_eps: 1e-12           # (float) A value added to the denominator for numerical stability.
initializer_range: 0.02         # (float) The standard deviation for normal initialization.
loss_type: CE                   # (str) The type of loss function. Range in [CE, BPR].
dnn_type: trm                   # (str) The type of DNN. Range in [trm, ave].

sess_dropout: 0.2               # (float) The probability of item embeddings in a session to be zeroed.
item_dropout: 0.2               # (float) The probability of candidate item embeddings to be zeroed.
temperature: 0.07               # (float) Temperature for contrastive loss.
