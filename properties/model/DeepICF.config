[model]
embedding_dim=64
mlp_hidden_size=[64,128,64]
attention_dim=32
beta=0.8
alpha=0
regs=[1e-6,10]

split_to=0